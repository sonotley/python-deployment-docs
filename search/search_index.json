{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction What is this all about? Python is pretty easy to write, but when it comes to packaging, distributing and running code somewhere other than your own computer, things get a bit tricky. This is a guide to how I've chosen to tackle that problem. It's a reference for my future self and hopefully of help to other people too. Who is this for? In general, I have two target use-cases when I'm writing code, if you have similar needs perhaps you'll find this site useful. I'm providing a utility for users to use on their workstations - generally Windows PCs I'm proving software to be run as a service on a server, often Windows but sometimes Linux These two use-cases share some similarities: I can't guarantee the version of Python (or even the existence of Python) on the target system I don't want the installer or user to need to know any Python or to do lots of setup work, it needs to just install and work I don't want the deployed code to be scattered around non-obvious places, ideally everything should be in one directory so it can be uninstalled simply by deleting that directory In the case of deployment to a server there is an important addition to the third point above: The installed software must not be dependent on the continued existence of the user account by which it was installed. Who is this not for? Well, I like to think anyone with an interest in Python could get something from these pages, but there are a few area I'm not planning on addressing simply because they aren't options I generally use. They aren't bad options, they just aren't part of the environment I'm currently working in. They are: Deploying software as a Docker container Deploying to 'serverless' cloud services such as Google App Engine, AWS Lambda, Heroku I also don't really cover the online CI/CD tools such as those provided Github and Gitlab. I'd like to explore these, but they aren't in my current workflow. My dev environment","title":"Introduction"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#what-is-this-all-about","text":"Python is pretty easy to write, but when it comes to packaging, distributing and running code somewhere other than your own computer, things get a bit tricky. This is a guide to how I've chosen to tackle that problem. It's a reference for my future self and hopefully of help to other people too.","title":"What is this all about?"},{"location":"#who-is-this-for","text":"In general, I have two target use-cases when I'm writing code, if you have similar needs perhaps you'll find this site useful. I'm providing a utility for users to use on their workstations - generally Windows PCs I'm proving software to be run as a service on a server, often Windows but sometimes Linux These two use-cases share some similarities: I can't guarantee the version of Python (or even the existence of Python) on the target system I don't want the installer or user to need to know any Python or to do lots of setup work, it needs to just install and work I don't want the deployed code to be scattered around non-obvious places, ideally everything should be in one directory so it can be uninstalled simply by deleting that directory In the case of deployment to a server there is an important addition to the third point above: The installed software must not be dependent on the continued existence of the user account by which it was installed.","title":"Who is this for?"},{"location":"#who-is-this-not-for","text":"Well, I like to think anyone with an interest in Python could get something from these pages, but there are a few area I'm not planning on addressing simply because they aren't options I generally use. They aren't bad options, they just aren't part of the environment I'm currently working in. They are: Deploying software as a Docker container Deploying to 'serverless' cloud services such as Google App Engine, AWS Lambda, Heroku I also don't really cover the online CI/CD tools such as those provided Github and Gitlab. I'd like to explore these, but they aren't in my current workflow. My dev environment","title":"Who is this not for?"},{"location":"dev/","text":"Development environment The basics My development environment consists of: Pycharm with Poetry plugin Poetry Git Pycharm is largely just a personal preference, you can follow this workflow with any IDE, or none. Similarly Git is central to how I share, backup and manage the history of my source code, but has no place in my deployment workflow other than as a way to get the source to the place it will be packaged. Poetry however, is pretty important. What is Poetry? I've never heard of it. Poetry is a fairly young project which provides an all-in-one solution to packaging and dependency management. I use Poetry because it makes it very easy to package my code up into something that someone else can pip install (or indeed poetry install but as you'll see, I don't want to rely on the target system having Poetry installed). The workflow When starting a new project, either create it using poetry new or select Poetry from the available interpreters in Pycharm. This will create a basic project structure including two packages, one for your source and one for your [tests]. It will also create a virtual environment (not in the project directory by default) and pyproject.toml file. The pyproject.toml seems to be the source of some mild controversy in the Python community, but we can ignore that. The great thing for us is that it's the only configuration file we need for our project. To install additional packages from PyPI, rather than using pip , just use poetry install . This will install the package into your environment and add it to the dependencies section of pyproject.toml . You can add dev dependencies with the --dev switch.","title":"Development environment"},{"location":"dev/#development-environment","text":"","title":"Development environment"},{"location":"dev/#the-basics","text":"My development environment consists of: Pycharm with Poetry plugin Poetry Git Pycharm is largely just a personal preference, you can follow this workflow with any IDE, or none. Similarly Git is central to how I share, backup and manage the history of my source code, but has no place in my deployment workflow other than as a way to get the source to the place it will be packaged. Poetry however, is pretty important.","title":"The basics"},{"location":"dev/#what-is-poetry-ive-never-heard-of-it","text":"Poetry is a fairly young project which provides an all-in-one solution to packaging and dependency management. I use Poetry because it makes it very easy to package my code up into something that someone else can pip install (or indeed poetry install but as you'll see, I don't want to rely on the target system having Poetry installed).","title":"What is Poetry? I've never heard of it."},{"location":"dev/#the-workflow","text":"When starting a new project, either create it using poetry new or select Poetry from the available interpreters in Pycharm. This will create a basic project structure including two packages, one for your source and one for your [tests]. It will also create a virtual environment (not in the project directory by default) and pyproject.toml file. The pyproject.toml seems to be the source of some mild controversy in the Python community, but we can ignore that. The great thing for us is that it's the only configuration file we need for our project. To install additional packages from PyPI, rather than using pip , just use poetry install . This will install the package into your environment and add it to the dependencies section of pyproject.toml . You can add dev dependencies with the --dev switch.","title":"The workflow"},{"location":"install/","text":"Installing on the target system When distributing my application to the target system, I provide a batch (Windows) and bash (Linux) scripts along with the wheel created by Poetry. I'll also provide a readme and any configuration or resource files required. The script does the following: Creates a directory in a location of the user's choosing Creates a virtual environment in an env subdirectory Activates the virtual environment and pip installs my project from the wheel Copies readme and resources into the target directory Makes a link to the script we declared in the pyproject.toml files (which by defaul is created several folders deep inside the virtual enviroment) at the top level of the new directory This leaves you with something like this, which looks remarkable like a 'normal' Windows application. You can double click the executable to run the app, or make it the target of a service and it will just work. my-app/ \u251c\u2500 env/ \u251c\u2500 resources/ \u251c\u2500 my-app.exe \u251c\u2500 readme.md \u251c\u2500 setup.yaml","title":"Installing on the target system"},{"location":"install/#installing-on-the-target-system","text":"When distributing my application to the target system, I provide a batch (Windows) and bash (Linux) scripts along with the wheel created by Poetry. I'll also provide a readme and any configuration or resource files required. The script does the following: Creates a directory in a location of the user's choosing Creates a virtual environment in an env subdirectory Activates the virtual environment and pip installs my project from the wheel Copies readme and resources into the target directory Makes a link to the script we declared in the pyproject.toml files (which by defaul is created several folders deep inside the virtual enviroment) at the top level of the new directory This leaves you with something like this, which looks remarkable like a 'normal' Windows application. You can double click the executable to run the app, or make it the target of a service and it will just work. my-app/ \u251c\u2500 env/ \u251c\u2500 resources/ \u251c\u2500 my-app.exe \u251c\u2500 readme.md \u251c\u2500 setup.yaml","title":"Installing on the target system"},{"location":"package/","text":"Packaging the project This part of things had me totally confused for a while. But it turns out recent improvements have made this somewhat simpler. Basically I wanted a way to allow a user to recreate my application and all its dependencies inside a virtual environment with zero Python knowledge and minimal complexity (for me and them). Packaging in Python is such a perenial topic of confusion and debate that there is actually an official organisation dedicated to it. The PYPA site is a useful resource but I found it wasn't particularly friendly to people just looking for a simple opinionated solution. My current method - Poetry As mentioned earlier, I use Poetry to manage dependencies and provide a virtual environment when developing. The great thing about Poetry is that packaging essentially comes for free. All I need to do is type poetry build and my project is packaged up into a tarball and a wheel. These contain my code and the metadata defining its dependencies. The metadata also records that Poetry is the tool required to build the package from source (i.e. the tarball, also known as an sdist). Doesn't that mean the user needs Poetry installed? No, thankfully not. That's one of the key reasons I chose this approach. Since PEP-517 and 518, pip looks in the pyproject.toml file to determine what build tools are required when installing a package from sdist, and retrieves these automatically. Alternatively, if you install from the wheel file... Why bother packaging at all, why not just distibute the code? First of all, in the case of pur Python packages your source code is distributed. Once someone has installed you package they can happily import it into their own projects or just browse your .py files. For the general Python community, the biggest advantage of packaging your code is that it means you can upload it to pypi, allowing others to discover and install it. Packaging is also an essential step if your code contains C extensions. However, I'm talking about distributing pur Python applications to users directly, so why bother? The answers: Scripts Version control Other things I looked at","title":"Packaging the project"},{"location":"package/#packaging-the-project","text":"This part of things had me totally confused for a while. But it turns out recent improvements have made this somewhat simpler. Basically I wanted a way to allow a user to recreate my application and all its dependencies inside a virtual environment with zero Python knowledge and minimal complexity (for me and them). Packaging in Python is such a perenial topic of confusion and debate that there is actually an official organisation dedicated to it. The PYPA site is a useful resource but I found it wasn't particularly friendly to people just looking for a simple opinionated solution.","title":"Packaging the project"},{"location":"package/#my-current-method-poetry","text":"As mentioned earlier, I use Poetry to manage dependencies and provide a virtual environment when developing. The great thing about Poetry is that packaging essentially comes for free. All I need to do is type poetry build and my project is packaged up into a tarball and a wheel. These contain my code and the metadata defining its dependencies. The metadata also records that Poetry is the tool required to build the package from source (i.e. the tarball, also known as an sdist).","title":"My current method - Poetry"},{"location":"package/#doesnt-that-mean-the-user-needs-poetry-installed","text":"No, thankfully not. That's one of the key reasons I chose this approach. Since PEP-517 and 518, pip looks in the pyproject.toml file to determine what build tools are required when installing a package from sdist, and retrieves these automatically. Alternatively, if you install from the wheel file...","title":"Doesn't that mean the user needs Poetry installed?"},{"location":"package/#why-bother-packaging-at-all-why-not-just-distibute-the-code","text":"First of all, in the case of pur Python packages your source code is distributed. Once someone has installed you package they can happily import it into their own projects or just browse your .py files. For the general Python community, the biggest advantage of packaging your code is that it means you can upload it to pypi, allowing others to discover and install it. Packaging is also an essential step if your code contains C extensions. However, I'm talking about distributing pur Python applications to users directly, so why bother? The answers: Scripts Version control","title":"Why bother packaging at all, why not just distibute the code?"},{"location":"package/#other-things-i-looked-at","text":"","title":"Other things I looked at"},{"location":"tldr/","text":"Quick reference Write software using Poetry to manage dependencies Write tests using Pytest Package the project to tarball and/or wheel using Poetry Automatically increment and single-source the version number Optionally, use Jenkins to automate and centralise packaging Use Tox to automatically runs the tests in isolated environment(s) Distribute the package to users Include a script to install the package in a self-contained virtual environment","title":"Quick reference"},{"location":"tldr/#quick-reference","text":"Write software using Poetry to manage dependencies Write tests using Pytest Package the project to tarball and/or wheel using Poetry Automatically increment and single-source the version number Optionally, use Jenkins to automate and centralise packaging Use Tox to automatically runs the tests in isolated environment(s) Distribute the package to users Include a script to install the package in a self-contained virtual environment","title":"Quick reference"},{"location":"write-tests/","text":"Writing tests Use pytest Unit testing is an area I'm still learning. I initially based my tests on this excellent article , particularly part 2 . However I found that two of its key recommendations, inheriting from unittest.TestCase and use of the parameterized package, seemed to make things harder when I came to do more complicated tests. For example it was difficult to find any help on how to use unittest.mock.patch (or my current choice, pytest-mock , which wraps this into mocker ) with parameterized. Sticking within the pytest package has made things easier in this regard. Therefore, my current approach to unit tests is to write bare functions (no classes) with plain assert statements. If I need to parameterize a function I use pytest.parametrize and if I need to patch something I use mocker from pytest-mock. For other mocking I use the classic unittest.MagicMock . Where possible I try to write code that avoids the need for patching during tests. I use dependency injection or callbacks such that if function A needs to call function B, function B is passed to function A as an argument. For example: code block here Test dependencies","title":"Writing tests"},{"location":"write-tests/#writing-tests","text":"","title":"Writing tests"},{"location":"write-tests/#use-pytest","text":"Unit testing is an area I'm still learning. I initially based my tests on this excellent article , particularly part 2 . However I found that two of its key recommendations, inheriting from unittest.TestCase and use of the parameterized package, seemed to make things harder when I came to do more complicated tests. For example it was difficult to find any help on how to use unittest.mock.patch (or my current choice, pytest-mock , which wraps this into mocker ) with parameterized. Sticking within the pytest package has made things easier in this regard. Therefore, my current approach to unit tests is to write bare functions (no classes) with plain assert statements. If I need to parameterize a function I use pytest.parametrize and if I need to patch something I use mocker from pytest-mock. For other mocking I use the classic unittest.MagicMock . Where possible I try to write code that avoids the need for patching during tests. I use dependency injection or callbacks such that if function A needs to call function B, function B is passed to function A as an argument. For example: code block here","title":"Use pytest"},{"location":"write-tests/#test-dependencies","text":"","title":"Test dependencies"}]}